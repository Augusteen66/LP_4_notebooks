{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4ee5dd95",
   "metadata": {},
   "source": [
    "## Assignment 6\n",
    "\n",
    "### Aagaaz Ali Sayed\n",
    "\n",
    "### 43369"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d27ce13b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn  # All neural network modules, nn.Linear, nn.Conv2d, BatchNorm, Loss functions\n",
    "import torch.optim as optim  # For all Optimization algorithms, SGD, Adam, etc.\n",
    "import torch.nn.functional as F  # All functions that don't have any parameters\n",
    "from torch.utils.data import (\n",
    "    DataLoader,\n",
    ")  # Gives easier dataset managment and creates mini batches\n",
    "import torchvision.datasets as datasets  # Has standard datasets we can import in a nice way\n",
    "import torchvision.transforms as transforms  # Transformations we can perform on our dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8c24d4a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Hyperparameters\n",
    "num_classes = 10\n",
    "learning_rate = 1e-3\n",
    "batch_size = 1024\n",
    "num_epochs = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "06c8e426",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple Identity class that let's input pass without changes\n",
    "class Identity(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Identity, self).__init__()\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9aeaf586",
   "metadata": {},
   "source": [
    "### 1. Load in a pretrained model (VGG16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ec3649c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torchvision.models.vgg16(pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e8b67b09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VGG(\n",
      "  (features): Sequential(\n",
      "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): ReLU(inplace=True)\n",
      "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (3): ReLU(inplace=True)\n",
      "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (6): ReLU(inplace=True)\n",
      "    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (8): ReLU(inplace=True)\n",
      "    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (11): ReLU(inplace=True)\n",
      "    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (13): ReLU(inplace=True)\n",
      "    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (15): ReLU(inplace=True)\n",
      "    (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (18): ReLU(inplace=True)\n",
      "    (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (20): ReLU(inplace=True)\n",
      "    (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (22): ReLU(inplace=True)\n",
      "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (25): ReLU(inplace=True)\n",
      "    (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (27): ReLU(inplace=True)\n",
      "    (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (29): ReLU(inplace=True)\n",
      "    (30): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n",
      "  (classifier): Sequential(\n",
      "    (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
      "    (1): ReLU(inplace=True)\n",
      "    (2): Dropout(p=0.5, inplace=False)\n",
      "    (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
      "    (4): ReLU(inplace=True)\n",
      "    (5): Dropout(p=0.5, inplace=False)\n",
      "    (6): Linear(in_features=4096, out_features=1000, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6a99436",
   "metadata": {},
   "source": [
    "### 2. Freezing parameters in model's lower layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "48e9153a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you want to do finetuning then set requires_grad = False\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "48e8588f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Freezing the average pool layer of the model and add a custom classifier\n",
    "model.avgpool = Identity()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3290f579",
   "metadata": {},
   "source": [
    "### 3. Add custom classifier with several layers of trainable parameters to mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e01d25a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VGG(\n",
       "  (features): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (3): ReLU(inplace=True)\n",
       "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (6): ReLU(inplace=True)\n",
       "    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (8): ReLU(inplace=True)\n",
       "    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (11): ReLU(inplace=True)\n",
       "    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (13): ReLU(inplace=True)\n",
       "    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (15): ReLU(inplace=True)\n",
       "    (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (18): ReLU(inplace=True)\n",
       "    (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (20): ReLU(inplace=True)\n",
       "    (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (22): ReLU(inplace=True)\n",
       "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (25): ReLU(inplace=True)\n",
       "    (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (27): ReLU(inplace=True)\n",
       "    (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (29): ReLU(inplace=True)\n",
       "    (30): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (avgpool): Identity()\n",
       "  (classifier): Sequential(\n",
       "    (0): Linear(in_features=512, out_features=100, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=100, out_features=10, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.classifier = nn.Sequential(\n",
    "    nn.Linear(512, 100), nn.ReLU(), \n",
    "    nn.Linear(100, num_classes)\n",
    ")\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d3f36b4",
   "metadata": {},
   "source": [
    "### 4. Train classifier layers on training data available for task\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9a0a3cea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "# Load Data\n",
    "train_dataset = datasets.CIFAR10(\n",
    "    root=\"dataset/\", train=True, transform=transforms.ToTensor(), download=True\n",
    ")\n",
    "train_loader = DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c2e1d335",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "922c2df4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost at epoch 0 is 1.60167\n",
      "Cost at epoch 1 is 1.21673\n",
      "Cost at epoch 2 is 1.14774\n",
      "Cost at epoch 3 is 1.11342\n",
      "Cost at epoch 4 is 1.09066\n",
      "Cost at epoch 5 is 1.07540\n",
      "Cost at epoch 6 is 1.06142\n",
      "Cost at epoch 7 is 1.05008\n",
      "Cost at epoch 8 is 1.03961\n",
      "Cost at epoch 9 is 1.03071\n",
      "Cost at epoch 10 is 1.02185\n",
      "Cost at epoch 11 is 1.01210\n",
      "Cost at epoch 12 is 1.00365\n",
      "Cost at epoch 13 is 0.99749\n",
      "Cost at epoch 14 is 0.98717\n",
      "Cost at epoch 15 is 0.98001\n",
      "Cost at epoch 16 is 0.97341\n",
      "Cost at epoch 17 is 0.96476\n",
      "Cost at epoch 18 is 0.95669\n",
      "Cost at epoch 19 is 0.94882\n",
      "Cost at epoch 20 is 0.94058\n",
      "Cost at epoch 21 is 0.93216\n",
      "Cost at epoch 22 is 0.92514\n",
      "Cost at epoch 23 is 0.91983\n",
      "Cost at epoch 24 is 0.91106\n",
      "Cost at epoch 25 is 0.90328\n",
      "Cost at epoch 26 is 0.89626\n",
      "Cost at epoch 27 is 0.88860\n",
      "Cost at epoch 28 is 0.88251\n",
      "Cost at epoch 29 is 0.87437\n",
      "Cost at epoch 30 is 0.86890\n",
      "Cost at epoch 31 is 0.86242\n",
      "Cost at epoch 32 is 0.85475\n",
      "Cost at epoch 33 is 0.84815\n",
      "Cost at epoch 34 is 0.84148\n",
      "Cost at epoch 35 is 0.83544\n",
      "Cost at epoch 36 is 0.82929\n",
      "Cost at epoch 37 is 0.82239\n",
      "Cost at epoch 38 is 0.81632\n",
      "Cost at epoch 39 is 0.81004\n",
      "Cost at epoch 40 is 0.80643\n",
      "Cost at epoch 41 is 0.79899\n",
      "Cost at epoch 42 is 0.79274\n",
      "Cost at epoch 43 is 0.78802\n",
      "Cost at epoch 44 is 0.78175\n",
      "Cost at epoch 45 is 0.77579\n",
      "Cost at epoch 46 is 0.76945\n",
      "Cost at epoch 47 is 0.76623\n",
      "Cost at epoch 48 is 0.75799\n",
      "Cost at epoch 49 is 0.75369\n",
      "Cost at epoch 50 is 0.74817\n",
      "Cost at epoch 51 is 0.74223\n",
      "Cost at epoch 52 is 0.73710\n",
      "Cost at epoch 53 is 0.73218\n",
      "Cost at epoch 54 is 0.72751\n",
      "Cost at epoch 55 is 0.72207\n",
      "Cost at epoch 56 is 0.71735\n",
      "Cost at epoch 57 is 0.71114\n",
      "Cost at epoch 58 is 0.70759\n",
      "Cost at epoch 59 is 0.70326\n",
      "Cost at epoch 60 is 0.69960\n",
      "Cost at epoch 61 is 0.69346\n",
      "Cost at epoch 62 is 0.68908\n",
      "Cost at epoch 63 is 0.68302\n",
      "Cost at epoch 64 is 0.67911\n",
      "Cost at epoch 65 is 0.67746\n",
      "Cost at epoch 66 is 0.67193\n",
      "Cost at epoch 67 is 0.66781\n",
      "Cost at epoch 68 is 0.66291\n",
      "Cost at epoch 69 is 0.65854\n",
      "Cost at epoch 70 is 0.65476\n",
      "Cost at epoch 71 is 0.65271\n",
      "Cost at epoch 72 is 0.64799\n",
      "Cost at epoch 73 is 0.64210\n",
      "Cost at epoch 74 is 0.63759\n",
      "Cost at epoch 75 is 0.63567\n",
      "Cost at epoch 76 is 0.63068\n",
      "Cost at epoch 77 is 0.62776\n",
      "Cost at epoch 78 is 0.62360\n",
      "Cost at epoch 79 is 0.61910\n",
      "Cost at epoch 80 is 0.61743\n",
      "Cost at epoch 81 is 0.61326\n",
      "Cost at epoch 82 is 0.60869\n",
      "Cost at epoch 83 is 0.60422\n",
      "Cost at epoch 84 is 0.60248\n",
      "Cost at epoch 85 is 0.59900\n",
      "Cost at epoch 86 is 0.59578\n",
      "Cost at epoch 87 is 0.59204\n",
      "Cost at epoch 88 is 0.59003\n",
      "Cost at epoch 89 is 0.58550\n",
      "Cost at epoch 90 is 0.58382\n",
      "Cost at epoch 91 is 0.58084\n",
      "Cost at epoch 92 is 0.57541\n",
      "Cost at epoch 93 is 0.57123\n",
      "Cost at epoch 94 is 0.56964\n",
      "Cost at epoch 95 is 0.56597\n",
      "Cost at epoch 96 is 0.56284\n",
      "Cost at epoch 97 is 0.56100\n",
      "Cost at epoch 98 is 0.55754\n",
      "Cost at epoch 99 is 0.55569\n"
     ]
    }
   ],
   "source": [
    "# Train Network\n",
    "for epoch in range(num_epochs):\n",
    "    losses = []\n",
    "\n",
    "    for batch_idx, (data, targets) in enumerate(train_loader):\n",
    "        # Get data to cuda if possible\n",
    "        data = data.to(device=device)\n",
    "        targets = targets.to(device=device)\n",
    "\n",
    "        # forward\n",
    "        scores = model(data)\n",
    "        loss = criterion(scores, targets)\n",
    "\n",
    "        losses.append(loss.item())\n",
    "        # backward\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "\n",
    "        # gradient descent or adam step\n",
    "        optimizer.step()\n",
    "\n",
    "    print(f\"Cost at epoch {epoch} is {sum(losses)/len(losses):.5f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c5c455c",
   "metadata": {},
   "source": [
    "### 5. Checking accuracy and fine tuning if required."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "97407cc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_accuracy(loader, model):\n",
    "    if loader.dataset.train:\n",
    "        print(\"Checking accuracy on training data\")\n",
    "    else:\n",
    "        print(\"Checking accuracy on test data\")\n",
    "\n",
    "    num_correct = 0\n",
    "    num_samples = 0\n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for x, y in loader:\n",
    "            x = x.to(device=device)\n",
    "            y = y.to(device=device)\n",
    "\n",
    "            scores = model(x)\n",
    "            _, predictions = scores.max(1)\n",
    "            num_correct += (predictions == y).sum()\n",
    "            num_samples += predictions.size(0)\n",
    "\n",
    "        print(\n",
    "            f\"Got {num_correct} / {num_samples} with accuracy {float(num_correct)/float(num_samples)*100:.2f}\"\n",
    "        )\n",
    "\n",
    "    model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6caeab4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking accuracy on training data\n",
      "Got 41169 / 50000 with accuracy 82.34\n"
     ]
    }
   ],
   "source": [
    "check_accuracy(train_loader, model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
